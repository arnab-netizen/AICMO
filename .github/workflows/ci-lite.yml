name: ci-lite

on:
  push:
    branches: [ main ]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ci-lite-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint-yaml:
    name: Lint YAML
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Lint YAML (placeholder)
        run: |
          echo "Skipping detailed yamllint in this environment."

  fast-sqlite:
    name: fast-sqlite (advisory SQLite autogenerate)
    runs-on: ubuntu-latest
    env:
      # Provide a local SQLite URL so alembic's env.py can run online migrations
      DATABASE_URL: sqlite:///./.ci_fast_sqlite.db
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install minimal deps for autogenerate
        run: |
          python -m pip install --upgrade pip
          pip install alembic sqlalchemy

      - name: Advisory SQLite autogenerate (write to .alembic_autogen/drift)
        run: |
          python - <<'PY'
          import os, pathlib, tempfile
          from alembic.config import Config
          from alembic import command
          from alembic import util as alembic_util

          cfg = Config('backend/alembic.ini')
          tmp = pathlib.Path(tempfile.mkdtemp(prefix='alembic_sqlite_'))
          out = tmp / 'versions'
          out.mkdir(parents=True, exist_ok=True)

          db_url = os.environ.get('DATABASE_URL','') or ''
          is_sqlite = db_url.startswith('sqlite')

          # For advisory SQLite probe we avoid applying Postgres-specific DDL
          # and tolerate autogenerate errors. This step must not fail CI.
          try:
              if not is_sqlite:
                  try:
                      cfg.set_main_option('sqlalchemy.url', db_url)
                      command.upgrade(cfg, 'head')
                  except Exception as e:
                      print('[warn] alembic upgrade head (sqlite advisory) failed:', e)

              try:
                  # attempt autogenerate; on sqlite DB mismatch this may raise
                  command.revision(cfg, message='DRIFT_PROBE_SQLITE', autogenerate=True, version_path=str(out))
              except alembic_util.CommandError as ce:
                  # Treat as advisory: report and continue without failing job
                  print('[warn] alembic autogenerate produced CommandError (advisory):', ce)
              except SystemExit:
                  # alembic sometimes sys.exit(0)
                  pass
              except Exception as e:
                  print('[warn] alembic autogenerate unexpected error (advisory):', e)
          except Exception:
              # ensure we never raise from advisory probe
              pass

          dst = pathlib.Path('.alembic_autogen/drift')
          dst.mkdir(parents=True, exist_ok=True)
          for f in out.glob('*.py'):
              (dst / f.name).write_text(f.read_text(encoding='utf-8'))
          print('Wrote advisory sqlite autogen to', dst)
          PY

  tests:
    name: tests (apply migrations + run pytest)
    runs-on: ubuntu-latest
    needs: fast-sqlite
    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_USER: aicmo
          POSTGRES_PASSWORD: pass
          POSTGRES_DB: aicmo
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U aicmo -d aicmo"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10
    # Do not set DATABASE_URL at the job level to avoid premature DNS lookups.
    # The Prep DB step will resolve and persist a working URL into $GITHUB_ENV.
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Preflight checks
        run: |
          set -euo pipefail
          echo "[preflight] verify required files and env"
          if [ ! -f backend/requirements.txt ]; then echo "Missing backend/requirements.txt" >&2; exit 1; fi
          # Accept either requirements-test.txt or requirements-dev.txt for test deps
          if [ ! -f backend/requirements-test.txt ] && [ ! -f backend/requirements-dev.txt ]; then
            echo "Missing backend/requirements-test.txt AND backend/requirements-dev.txt" >&2; exit 1;
          fi
          # DATABASE_URL may be provided later in the job (we avoid setting it at job level)
          # so don't fail preflight if it's not present yet — warn instead.
          if [ -z "${DATABASE_URL:-}" ]; then
            echo "[warn] DATABASE_URL not set yet; will be resolved in a later step"
          else
            case "$DATABASE_URL" in
              postgresql*|postgresql+* ) echo "[preflight] DATABASE_URL looks like Postgres" ;;
              *) echo "[warn] DATABASE_URL does not look like Postgres: $DATABASE_URL" ;;
            esac
          fi

      - name: Install deps
        run: |
          # Create an isolated venv and explicitly install into it. We then
          # expose the venv bin directory via GITHUB_ENV so subsequent steps
          # use the same interpreter and installed packages.
          set -euo pipefail
          python -m venv .venv
          . .venv/bin/activate
          VENV_PY=.venv/bin/python

          echo "[dbg] venv python:" $($VENV_PY -V 2>&1)
          echo "[dbg] which python:" $(which python)
          echo "[dbg] pip (venv) info:" $($VENV_PY -m pip --version 2>&1)

          $VENV_PY -m pip install --upgrade pip
          # Install pinned project dependencies into the venv
          $VENV_PY -m pip install -r backend/requirements.txt
          # Ensure Alembic is available for visibility checks and programmatic use
          $VENV_PY -m pip install alembic
          # Install local editable packages so test suite can import them (e.g. capsule_core)
          if [ -d "./capsule-core" ]; then
            echo "Installing local package ./capsule-core into venv"
            $VENV_PY -m pip install -e ./capsule-core
          else
            echo "Local package ./capsule-core not found; skipping editable install"
          fi
          # Install Temporal client library required by some backend modules/tests
          $VENV_PY -m pip install "temporalio>=1.18.0"
          # Install test/dev requirements if available. Prefer requirements-test.txt
          if [ -f backend/requirements-test.txt ]; then
            echo "Using backend/requirements-test.txt"
            $VENV_PY -m pip install -r backend/requirements-test.txt
          elif [ -f backend/requirements-dev.txt ]; then
            echo "Using backend/requirements-dev.txt"
            $VENV_PY -m pip install -r backend/requirements-dev.txt
          else
            echo "No test requirements file found; continuing without extra test deps"
          fi

          # Export the venv bin dir into PATH for subsequent steps
          echo "PATH=$(pwd)/.venv/bin:$PATH" >> $GITHUB_ENV
          # Provide a quick verification that temporalio is installed in the venv
          echo "[dbg] temporalio (venv) ->" $($VENV_PY -m pip show temporalio 2>/dev/null || echo "not-installed")

      - name: Prep DB + migrate
        run: |
          # Ensure a DATABASE_URL is available for the prep step; if it's not set yet,
          # fall back to the service hostname (this is safe for initial connectivity checks
          # and will be replaced later if a resolved SQLALCHEMY_URL is computed).
          if [ -z "${DATABASE_URL:-}" ]; then
            echo "[warn] DATABASE_URL not set for Prep DB; falling back to service hostname 'postgres'"
            export DATABASE_URL="postgresql+psycopg2://aicmo:pass@postgres:5432/aicmo"
          fi

          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          # Normalize DATABASE_URL to a psql-friendly form (remove +driver)
          PSQL_URL=$(python - <<'PY'
          import os, re
          u = os.environ['DATABASE_URL']
          print(re.sub(r'^(postgresql)(?:\+[^:]+)?://','postgresql://', u))
          PY
          )

          # In GitHub Actions we map the Postgres service port to localhost:5432.
          # Prefer connecting via localhost to avoid intermittent Docker DNS resolution
          # issues for the service hostname 'postgres'. Always normalize to localhost here.
          TRY_PSQL=$(echo "$PSQL_URL" | sed -E 's/@[^:]+:/@localhost:/')

          # Persist TRY_PSQL for later psql invocations in subsequent steps
          if [ -n "${TRY_PSQL:-}" ]; then
            echo "[dbg] Persisting TRY_PSQL for later steps"
            echo "TRY_PSQL=$TRY_PSQL" >> $GITHUB_ENV
          fi

          # Extract host/port for an explicit pg_isready check
          PSQL_HOST=$(echo "$TRY_PSQL" | sed -E 's#.*@([^:/]+):([0-9]+)/.*#\1#')
          PSQL_PORT=$(echo "$TRY_PSQL" | sed -E 's#.*@([^:/]+):([0-9]+)/.*#\2#')

          # Wait for Postgres to become ready (try up to ~60s)
          for i in {1..60}; do
            if pg_isready -q -h "${PSQL_HOST:-localhost}" -p "${PSQL_PORT:-5432}" -U aicmo -d aicmo; then
              echo "[dbg] Postgres ready on ${PSQL_HOST:-localhost}:${PSQL_PORT:-5432}"
              break
            fi
            sleep 1
          done

          # Ensure subprocesses (alembic/sqlalchemy) use the same host/port
          # Derive a sync SQLAlchemy URL (postgresql+psycopg2) from TRY_PSQL and export it
          # TRY_PSQL may be like: postgresql://user:pass@host:port/db
          # Convert to postgresql+psycopg2://user:pass@host:port/db
          SQLALCHEMY_URL=$(echo "$TRY_PSQL" | sed -E 's#^postgresql://#postgresql+psycopg2://#')
          if [ -n "$SQLALCHEMY_URL" ]; then
            echo "[dbg] Persisting SQLALCHEMY_URL so later steps (alembic/sqlalchemy) use the resolved host"
            # Persist into GITHUB_ENV so subsequent steps see the resolved URL
            echo "SQLALCHEMY_URL=$SQLALCHEMY_URL" >> $GITHUB_ENV
            echo "DATABASE_URL=$SQLALCHEMY_URL" >> $GITHUB_ENV
            echo "[dbg] SQLALCHEMY_URL set to: $SQLALCHEMY_URL"
          fi

          echo "[dbg] Using TRY_PSQL='$TRY_PSQL' for schema cleanup"
          # Quick validation: ensure psql can connect before attempting destructive ops
          if ! psql "$TRY_PSQL" -c '\l' >/dev/null 2>&1; then
            echo "[err] psql cannot connect using TRY_PSQL='$TRY_PSQL'" >&2
            # Dump environment for debugging
            env | sort
            exit 1
          fi

          # Clean schema each run
          psql "$TRY_PSQL" -c "DROP SCHEMA IF EXISTS public CASCADE; CREATE SCHEMA public;"

      - name: Single-head guard
        run: |
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          python - <<'PY'
          from alembic.config import Config
          from alembic.script import ScriptDirectory
          cfg = Config('backend/alembic.ini')
          sd = ScriptDirectory.from_config(cfg)
          heads = list(sd.get_heads())
          if len(heads) != 1:
            print('Multiple Alembic heads!', heads)
            raise SystemExit(1)
          print('[dbg] Alembic single head OK:', heads)
          PY

      - name: Apply migrations to head (Python)
        run: |
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          echo "[dbg] About to run alembic via python"
          echo "[dbg] SQLALCHEMY_URL='$SQLALCHEMY_URL'"
          echo "[dbg] DATABASE_URL='$DATABASE_URL'"
          python - <<'PY'
          import os, traceback
          from alembic.config import Config
          from alembic import command

          # Optional import for connectivity probing; if unavailable we'll skip the probe
          try:
              from sqlalchemy import create_engine, text
          except Exception:
              create_engine = None

          cfg = Config('backend/alembic.ini')
          # Prefer SQLALCHEMY_URL set by the step (sync psycopg2 URL pointing to resolved host)
          url = os.environ.get('SQLALCHEMY_URL') or os.environ.get('DATABASE_URL')
          print('[dbg] python alembic will use URL:', url)
          print('[dbg] env SQLALCHEMY_URL:', os.environ.get('SQLALCHEMY_URL'))
          print('[dbg] env DATABASE_URL:', os.environ.get('DATABASE_URL'))
          if url:
              cfg.set_main_option('sqlalchemy.url', url)

          # Quick connectivity test from the same Python process that will call Alembic
          if create_engine and url:
              try:
                  eng = create_engine(url)
                  with eng.connect() as conn:
                      conn.execute(text('SELECT 1'))
                  print('[dbg] python process DB connectivity OK')
              except Exception as conn_e:
                  print('[err] python process DB connectivity test failed:')
                  traceback.print_exc()

          try:
              command.upgrade(cfg, 'head')
          except SystemExit:
              # Alembic sometimes calls sys.exit(0) — treat as success
              pass
          except Exception:
              print('[err] alembic upgrade failed: full traceback follows')
              traceback.print_exc()
              # Re-raise so the job fails and the artifact steps run (we want failure visibility)
              raise
          PY

          # === Schema asserts (fail fast) ===
          # Compute an effective psql connection string. Prefer TRY_PSQL (persisted earlier),
          # otherwise fall back to DATABASE_URL, then SQLALCHEMY_URL, finally a localhost fallback.
          EFFECTIVE_PSQL="${TRY_PSQL:-${DATABASE_URL:-${SQLALCHEMY_URL:-}}}"
          if [ -z "$EFFECTIVE_PSQL" ]; then
            echo "[warn] No connection string available from TRY_PSQL/DATABASE_URL/SQLALCHEMY_URL; using localhost fallback"
            EFFECTIVE_PSQL="postgresql://aicmo:pass@localhost:5432/aicmo"
          fi
          # Strip any "+driver" prefix so psql accepts the URI format
          EFFECTIVE_PSQL=$(echo "$EFFECTIVE_PSQL" | sed -E 's#^postgresql\+[^:]+://#postgresql://#')

          # Robust check: ensure the DB's alembic_version matches the repository head.
          # This is a stronger signal that `alembic upgrade head` actually applied the current head
          # and avoids brittle object-level assertions when migrations intentionally drop objects.
          REPO_HEAD=$(python - <<'PY'
          from alembic.config import Config
          from alembic.script import ScriptDirectory
          cfg = Config('backend/alembic.ini')
          sd = ScriptDirectory.from_config(cfg)
          hs = list(sd.get_heads())
          print(hs[0] if hs else '')
          PY
          )

          if [ -z "$REPO_HEAD" ]; then
            echo "[warn] Could not determine repository alembic head; skipping alembic_version check"
          else
            echo "[dbg] expecting alembic head: $REPO_HEAD"
            # query the DB for the current alembic_version and require it match the repo head
            DB_HEAD=$(psql "$EFFECTIVE_PSQL" -Atc "SELECT version_num FROM alembic_version LIMIT 1;" || true)
            if [ "$DB_HEAD" != "$REPO_HEAD" ]; then
              echo "[err] alembic_version mismatch: db=$DB_HEAD repo=$REPO_HEAD" >&2
              exit 1
            fi
            echo "[dbg] alembic_version matches repo head: $REPO_HEAD"
          fi

          # Keep the older object-level checks as advisory logs (don't fail CI) to aid debugging
          psql "$EFFECTIVE_PSQL" -Atc "SELECT 1 FROM pg_indexes WHERE tablename='site' AND indexname='ux_site_slug';" | grep 1 || echo "[adv] ux_site_slug missing"
          psql "$EFFECTIVE_PSQL" -Atc "SELECT indexdef FROM pg_indexes WHERE tablename='page' AND indexdef LIKE '%UNIQUE% (site_id, path)%';" | grep UNIQUE || echo "[adv] page unique index missing"
          psql "$EFFECTIVE_PSQL" -Atc "SELECT table_name FROM information_schema.views WHERE table_schema='public' AND table_name='site_spec';" | grep site_spec || echo "[adv] site_spec view missing"

      - name: Alembic visibility check
        working-directory: .
        run: |
          set -e
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          echo "CWD: $(pwd)"
          echo "Repo root listing:"
          ls -la
          echo "Alembic files:"
          ls -la backend/alembic || true
          ls -la backend/alembic/versions || true

          python - <<'PY'
          import os, glob
          from alembic.config import Config
          from alembic.script import ScriptDirectory

          cfg = Config("backend/alembic.ini")
          print("alembic.ini found:", os.path.exists("backend/alembic.ini"))
          print("cfg.config_file_name:", cfg.config_file_name)
          print("script_location cfg:", cfg.get_main_option("script_location"))

          versions = glob.glob("backend/alembic/versions/*.py")
          print("versions count:", len(versions))
          for v in sorted(versions)[-5:]:
              print("  -", os.path.basename(v))

          script = ScriptDirectory.from_config(cfg)
          print("heads:", list(script.get_heads()))
          print("bases:", list(script.get_bases()))
          PY

      - name: Ensure DB client + driver and set DATABASE_URL
        run: |
          # Ensure we use the venv created earlier if present
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi

          python -m pip install --upgrade pip
          python -m pip install psycopg2-binary sqlalchemy
          # If a resolved SQLALCHEMY_URL (or DATABASE_URL) was persisted earlier, do not overwrite it.
          if [ -n "${SQLALCHEMY_URL:-}" ]; then
            echo "[dbg] SQLALCHEMY_URL already set; exporting as DATABASE_URL"
            echo "DATABASE_URL=${SQLALCHEMY_URL}" >> $GITHUB_ENV
          elif [ -z "${DATABASE_URL:-}" ]; then
            # Fallback: use localhost (service port is mapped to the runner) to avoid DNS issues
            echo "[dbg] DATABASE_URL not present; setting fallback to localhost"
            echo "DATABASE_URL=postgresql+psycopg2://aicmo:pass@localhost:5432/aicmo" >> $GITHUB_ENV
          else
            echo "[dbg] DATABASE_URL already present; not overwriting"
          fi

          # Sanity check the connection using whichever DATABASE_URL will be visible to subsequent steps
          python - <<'PY'
          import os
          from sqlalchemy import create_engine, text
          url = os.environ.get("DATABASE_URL") or os.environ.get("SQLALCHEMY_URL")
          if not url:
              print("[warn] No DATABASE_URL/SQLALCHEMY_URL set; skipping DB connectivity check")
          else:
              eng = create_engine(url, pool_pre_ping=True)
              with eng.connect() as c:
                  c.execute(text("SELECT 1"))
              print("[dbg] DB connectivity OK:", url)
          PY

      - name: Alembic heads/current (no DB) — prove versions are visible
        working-directory: .
        run: |
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          python - <<'PY'
          from alembic.config import Config
          from alembic.script import ScriptDirectory
          cfg = Config("backend/alembic.ini")
          print("[dbg] config_file_name =", cfg.config_file_name)
          print("[dbg] script_location  =", cfg.get_main_option("script_location"))
          sd = ScriptDirectory.from_config(cfg)
          heads = list(sd.get_heads())
          bases = list(sd.get_bases())
          print("[dbg] heads =", heads)
          print("[dbg] bases =", bases)
          assert heads, "No heads found — Alembic cannot see versions"
          PY

      - name: DB alembic_version (optional)
        if: ${{ env.DATABASE_URL != '' }}
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: |
          python - <<'PY'
          import os
          from sqlalchemy import create_engine, text
          url = os.environ.get("DATABASE_URL","")
          if not url:
              print("[dbg] No DATABASE_URL set; skipping DB version check.")
          else:
              print("[dbg] DATABASE_URL present; querying alembic_version …")
              eng = create_engine(url, future=True)
              with eng.connect() as c:
                  try:
                      v = c.execute(text("SELECT version_num FROM alembic_version")).scalar()
                      print("[dbg] alembic_version.version_num =", v)
                  except Exception as e:
                      print("[dbg] Could not read alembic_version:", e)
          PY

      - name: Upgrade DB to head (authoritative)
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: |
          set -e
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          python -c "import sys; import psycopg2, sqlalchemy; print('drivers ok')"
          # Ensure DB is at head before we try to autogenerate
          alembic -c backend/alembic.ini upgrade head
          echo "DB is at head ✅"

      - name: Dump offline SQL of current head (artifact for auditing)
        if: always()
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: |
          set -e
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          mkdir -p artifacts
          # capture the SQL (won't modify DB) for auditing
          alembic -c backend/alembic.ini upgrade head --sql > artifacts/upgrade_to_head.sql || true

      - name: Autogenerate & detect drift (temporary script dir)
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: |
          set -e
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          python - <<'PY'
          import pathlib, tempfile, sys, os, shutil
          from alembic.config import Config
          from alembic.script import ScriptDirectory
          from alembic import command

          cfg = Config('backend/alembic.ini')

          # Defensive: try to ensure DB is at head (no-op if already at head)
          try:
              command.upgrade(cfg, 'head')
          except SystemExit:
              pass
          except Exception:
              # don't fail here; we want a clear failure only if autogenerate produces files
              pass

          # use a temporary script_location so repo versions are not modified
          tmpdir = pathlib.Path(tempfile.mkdtemp(prefix='alembic_probe_'))
          cfg.set_main_option('script_location', str(tmpdir))
          (tmpdir / 'versions').mkdir(parents=True, exist_ok=True)

          # Ensure Alembic can still see repo versions by setting version_locations
          repo_versions = os.path.abspath('backend/alembic/versions')
          cfg.set_main_option('version_locations', f"{tmpdir / 'versions'},{repo_versions}")

          # Try autogenerate into the temp dir
          try:
              command.revision(cfg, message='DRIFT_PROBE', autogenerate=True)
          except SystemExit:
              pass
          except Exception:
              # Alembic autogenerate can be noisy; we'll inspect the temp versions dir below
              pass

          vers = tmpdir / 'versions'
          files = sorted(vers.glob('*.py'))
          if not files:
              print('No drift detected ✅')
              # cleanup
              try:
                  shutil.rmtree(tmpdir)
              except Exception:
                  pass
              sys.exit(0)

          # Drift detected: copy artifacts and fail with human-friendly output
          dst = pathlib.Path('.alembic_autogen/drift_pg')
          dst.mkdir(parents=True, exist_ok=True)
          print('Drift detected ❌. Alembic produced:')
          for f in files:
              print(' -', f)
              (dst / f.name).write_text(f.read_text(encoding='utf-8'))
              print(f.read_text())

          print('Wrote authoritative PG autogen to', dst)
          print('Keeping temp probe dir at', tmpdir)
          sys.exit(1)
          PY

      - name: Run tests (Postgres + SQLite)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          # Ensure we use the venv created earlier (do not rely on PATH propagation)
          if [ -f .venv/bin/activate ]; then
            . .venv/bin/activate
          else
            echo "[warn] .venv not present; using system python from setup-python"
          fi
          echo "[dbg] which python:" $(which python)
          echo "[dbg] python -V:" $(python -V)
          python -m pip show temporalio || true
          python -m pytest -q

      - name: Alembic visibility check (list heads from real script_location)
        working-directory: .
        run: |
          python - <<'PY'
          import os
          from alembic.config import Config
          from alembic.script import ScriptDirectory

          cfg = Config("backend/alembic.ini")
          script_location = cfg.get_main_option("script_location")
          print(f"[dbg] real script_location={script_location}")

          sd = ScriptDirectory.from_config(cfg)
          heads = list(sd.get_heads())
          print(f"[dbg] alembic heads count={len(heads)} -> {heads}")
          assert len(heads) >= 1, "No heads found — Alembic cannot see versions"
          PY

      - name: Prune non-probe files from PG drift artifact
        if: always()
        run: |
          set -euo pipefail
          ROOT=".alembic_autogen/drift_pg"
          [ -d "$ROOT" ] || exit 0
          echo "[guard] keeping files that match '*drift_probe*.py' only"
          # Ensure find options are ordered portably
          find "$ROOT" -maxdepth 2 -type f ! -name "*drift_probe*.py" -print -delete || true
          echo "[guard] remaining files:"; find "$ROOT" -maxdepth 2 -type f -print || true

      - name: Scan drift artifacts for destructive changes
        if: always()
        run: |
          python tools/scan_autogen_for_drops.py .alembic_autogen/drift_pg || (echo "Destructive tokens detected" && exit 1)

      - name: Upload debug artifacts (failure only)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-debug-artifacts
          path: |
            artifacts/**
            .alembic_autogen/**
            **/alembic_probe_*/*
