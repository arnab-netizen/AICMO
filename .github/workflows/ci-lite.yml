name: ci-lite

permissions:
  contents: read

concurrency:
  group: ci-lite-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [ main ]
  pull_request:
  schedule:
    - cron: '15 3 * * 1' # Mondays 03:15 UTC
  workflow_dispatch:

jobs:
  fast-sqlite:
    name: fast-sqlite (ci-lite) - quick sqlite + ruff
    runs-on: ubuntu-latest
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}  # may be empty
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install backend deps
        run: |
          python -m venv .venv
          . .venv/bin/activate
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt

      - name: Run quick sqlite tests
        run: . .venv/bin/activate && pytest -q backend/tests/test_db_sqlite.py backend/tests/test_db_utils.py -q

      - name: Alembic offline SQL render (smoke)
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
        run: |
          . .venv/bin/activate
          python -m pip install -r backend/requirements.txt || true
          alembic -c "$ALEMBIC_CONFIG" upgrade head --sql | head -n 5

      - name: Wait for Postgres
        if: >
          github.ref == 'refs/heads/main' ||
          contains(join(fromJson(toJson(github.event.pull_request.labels)).*.name, ','), 'needs-pg')
        run: |
          python - <<'PY'
          import os, time, sqlalchemy as sa
          url=os.environ.get('DATABASE_URL','').replace('+asyncpg','+psycopg2')
          for _ in range(30):
              try:
                  sa.create_engine(url).connect().close()
                  print('Postgres ready')
                  break
              except Exception as e:
                  print('waiting...', e)
                  time.sleep(2)
          else:
              raise SystemExit('Postgres not ready')
          PY

      - name: Run Alembic migrations (online)
        if: >
          github.ref == 'refs/heads/main' &&
          env.DATABASE_URL != '' &&
          startsWith(env.DATABASE_URL, 'postgresql')
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
          PYTHONPATH: ${{ github.workspace }}
        run: |
          . .venv/bin/activate
          pip install -r backend/requirements.txt
          pip install -e ./capsule-core
          alembic -c "$ALEMBIC_CONFIG" upgrade head

  drift_check:
    name: Alembic Drift Check
    runs-on: ubuntu-latest
    if: >
      github.ref == 'refs/heads/main' ||
      contains(join(fromJson(toJson(github.event.pull_request.labels)).*.name, ','), 'run-drift-check')
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
          pip install -e ./capsule-core

      - name: Schema smoke (metadata → SQLite)
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
          SQLALCHEMY_URL: sqlite:///${{ github.workspace }}/.alembic_tmp/drift.sqlite
          PYTHONPATH: ${{ github.workspace }}
        run: |
          rm -rf .alembic_tmp
          mkdir -p .alembic_tmp .alembic_autogen/drift
          python - <<'PY'
          import os
          from sqlalchemy import create_engine
          # import Base from backend package (PYTHONPATH is set)
          from backend.db.base import Base

          db_path = os.path.join(os.getcwd(), '.alembic_tmp', 'drift.sqlite')
          engine = create_engine(f"sqlite:///{db_path}")
          # Create tables according to model metadata — avoid executing migrations
          Base.metadata.create_all(bind=engine)
          print('Created sqlite drift DB:', db_path)
          PY

  drift_check_pg:
    name: Alembic Drift Check (Postgres)
    runs-on: ubuntu-latest
    # Label-gated: only run when PR has label 'run-drift-check-pg'
    if: >
      contains(join(fromJson(toJson(github.event.pull_request.labels)).*.name, ','), 'run-drift-check-pg')
    services:
      postgres:
        # fall back to an image with pgvector preinstalled when the secret DB
        # is not provided or is unreachable. This image is only pulled for
        # label-gated runs (keeps most PRs lightweight).
        image: ankane/pgvector:latest
        env:
          POSTGRES_PASSWORD: postgres
        ports: ['5432:5432']
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 5s
          --health-timeout 2s
          --health-retries 10
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
          pip install -e ./capsule-core

      - name: Pick effective DATABASE_URL (reachable-or-local)
        id: pickdb
        env:
          SECRET_DB_URL: ${{ secrets.DATABASE_URL }}
          LOCAL_URL: postgresql+psycopg://postgres:postgres@localhost:5432/postgres
        run: |
          set -e
          python - <<'PY'
          import os, sys
          out = open(os.environ["GITHUB_OUTPUT"], "a")
          secret = os.environ.get("SECRET_DB_URL","").strip()
          eff = os.environ.get("LOCAL_URL")
          def write(url, reason):
              print(f"Effective DATABASE_URL = {url} ({reason})")
              out.write(f"db_url={url}\n")
              out.close()
              sys.exit(0)

          if not secret:
              write(eff, "no secret provided")

          url = secret.replace("+asyncpg", "+psycopg").replace("+psycopg2", "+psycopg")
          if "supabase.co" in url and "sslmode=" not in url:
              sep = "&" if "?" in url else "?"
              url = f"{url}{sep}sslmode=require"

          print("Probing secret DATABASE_URL reachability...")
          try:
              import psycopg
              with psycopg.connect(url, connect_timeout=4) as conn:
                  with conn.cursor() as cur:
                      cur.execute("SELECT 1")
              write(url, "secret reachable")
          except Exception as e:
              print(f"Secret DB unreachable: {e!r}")
              write(eff, "fallback to local service")
          PY

      - name: Wait for local Postgres
        if: contains(steps.pickdb.outputs.db_url, 'localhost')
        run: |
          for i in $(seq 1 60); do
            if pg_isready -h localhost -p 5432 -U postgres; then
              echo "Local PG ready"; exit 0
            fi
            echo "Waiting for local PG..."
            sleep 2
          done
          echo "Local PG not ready"; exit 1

      - name: Print effective DB URL (before upgrade)
        env:
          DATABASE_URL: ${{ steps.pickdb.outputs.db_url }}
        run: |
          python - <<'PY'
          import os, re
          url = os.environ.get('DATABASE_URL') or os.environ.get('SQLALCHEMY_URL','')
          redacted = re.sub(r':\/\/([^:@]+):[^@]+@', r'://\1:***@', url)
          print('Effective DB URL:', redacted)
          PY

      - name: Ensure vector extension (best-effort)
        env:
          DATABASE_URL: ${{ steps.pickdb.outputs.db_url }}
        run: |
          # psql wants a libpq-style URL; strip any +driver suffix from the scheme
          PSQL_URL=$(python - <<'PY'
          import os, re
          u = os.environ.get('DATABASE_URL','')
          u = re.sub(r'^(postgresql)(?:\+[^:]+)?://', r'postgresql://', u)
          print(u)
          PY
          )
          echo "Trying to create vector extension on: ${PSQL_URL//:*@/:***@}"
          psql "$PSQL_URL" -c 'CREATE EXTENSION IF NOT EXISTS vector;' || true
      - name: Upgrade to head on Postgres
        env:
          PYTHONPATH: ${{ github.workspace }}
          ALEMBIC_CONFIG: backend/alembic.ini
          DATABASE_URL: ${{ steps.pickdb.outputs.db_url }}
        run: |
          alembic -c "$ALEMBIC_CONFIG" upgrade head

      - name: Print effective DB URL (before autogenerate)
        env:
          SQLALCHEMY_URL: ${{ steps.pickdb.outputs.db_url }}
        run: |
          python - <<'PY'
          import os, re
          url = os.environ.get('DATABASE_URL') or os.environ.get('SQLALCHEMY_URL','')
          redacted = re.sub(r':\/\/([^:@]+):[^@]+@', r'://\1:***@', url)
          print('Effective DB URL for autogenerate:', redacted)
          PY

      - name: Autogenerate & detect drift (PG)
        env:
          PYTHONPATH: ${{ github.workspace }}
          ALEMBIC_CONFIG: backend/alembic.ini
          SQLALCHEMY_URL: ${{ steps.pickdb.outputs.db_url }}
        run: |
          python - <<'PY'
          import pathlib, shutil, tempfile, sys, os
          from alembic.config import Config
          from alembic import command

          cfg = Config("backend/alembic.ini")
          tmp = pathlib.Path(tempfile.mkdtemp(prefix="alembic_drift_pg_"))
          outdir = pathlib.Path(".alembic_autogen/drift"); outdir.mkdir(parents=True, exist_ok=True)
          try:
              # Copy existing alembic env (env.py and helpers) into the temp
              # script_location so alembic can import env.py when autogenerating.
              import shutil
              shutil.copytree("backend/alembic", str(tmp), dirs_exist_ok=True)
              (tmp / "versions").mkdir(parents=True, exist_ok=True)

              cfg.set_main_option("script_location", str(tmp))
              # Ensure alembic env picks up the DB URL override when env.py runs
              cfg.set_main_option("sqlalchemy.url", os.environ.get('SQLALCHEMY_URL',''))
              command.revision(cfg, message="DRIFT_PROBE", autogenerate=True)
              vers = tmp / "versions"
              files = sorted(vers.glob("*.py")) if vers.exists() else []
              if not files:
                  print("No revision file created → no drift."); sys.exit(0)
              code = files[0].read_text()
              out = outdir / files[0].name; out.write_text(code)
              low = code.lower()
              tokens = ("op.create_table","op.alter_column","op.drop_table",
                        "op.add_column","op.drop_column","op.create_index","op.drop_index")
              if any(t in low for t in tokens):
                  print(f"Schema drift detected → see {out}"); sys.exit(1)
              print("Autogenerate produced a trivial/no-op file → no drift.")
          finally:
              shutil.rmtree(tmp, ignore_errors=True)
          PY

      - name: Upload PG drift artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: alembic-drift-autogen-pg
          path: .alembic_autogen/drift/**
          retention-days: 7

      - name: Autogenerate into temp dir and detect drift
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
          SQLALCHEMY_URL: sqlite:///${{ github.workspace }}/.alembic_tmp/drift.sqlite
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python - <<'PY'
          import pathlib, shutil, tempfile, sys
          from alembic.config import Config
          from alembic import command

          cfg = Config("backend/alembic.ini")
          tmp = pathlib.Path(tempfile.mkdtemp(prefix="alembic_drift_"))
          try:
              cfg.set_main_option("script_location", str(tmp))
              rev = command.revision(cfg, message="DRIFT_PROBE", autogenerate=True)
              vers = tmp / "versions"
              files = sorted(vers.glob("*.py")) if vers.exists() else []
              if not files:
                  print("No revision file created → no drift.")
                  sys.exit(0)
              code = files[0].read_text().lower()
              tokens = (
                  "op.create_table","op.alter_column","op.drop_table",
                  "op.add_column","op.drop_column","op.create_index","op.drop_index"
              )
              # copy to artifact dir for inspection
              outdir = pathlib.Path(".alembic_autogen/drift"); outdir.mkdir(parents=True, exist_ok=True)
              out = outdir / files[0].name
              out.write_text(code)
              if any(t in code for t in tokens):
                  print(f"Schema drift detected → see {out}")
                  sys.exit(1)
              print("Autogenerate produced a trivial/no-op file → no drift.")
          finally:
              shutil.rmtree(tmp, ignore_errors=True)
          PY

      - name: Upload drift artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: alembic-drift-autogen
          path: .alembic_autogen/drift/**
          retention-days: 7
