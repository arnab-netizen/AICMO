name: ci-lite

on:
  push:
    branches: [ main ]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ci-lite-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint-yaml:
    name: Lint YAML
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Lint YAML (placeholder)
        run: |
          echo "Skipping detailed yamllint in this environment."

  fast-sqlite:
    name: fast-sqlite (advisory SQLite autogenerate)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install minimal deps for autogenerate
        run: |
          python -m pip install --upgrade pip
          pip install alembic

      - name: Advisory SQLite autogenerate (write to .alembic_autogen/drift)
        run: |
          python - <<'PY'
          import os, pathlib, tempfile
          from alembic.config import Config
          from alembic import command

          cfg = Config('backend/alembic.ini')
          tmp = pathlib.Path(tempfile.mkdtemp(prefix='alembic_sqlite_'))
          out = tmp / 'versions'
          out.mkdir(parents=True, exist_ok=True)
          try:
              command.revision(cfg, message='DRIFT_PROBE_SQLITE', autogenerate=True, version_path=str(out))
          except SystemExit:
              pass

          dst = pathlib.Path('.alembic_autogen/drift')
          dst.mkdir(parents=True, exist_ok=True)
          for f in out.glob('*.py'):
              (dst / f.name).write_text(f.read_text(encoding='utf-8'))
          print('Wrote advisory sqlite autogen to', dst)
          PY

  tests:
    name: tests (apply migrations + run pytest)
    runs-on: ubuntu-latest
    needs: fast-sqlite
    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_USER: aicmo
          POSTGRES_PASSWORD: pass
          POSTGRES_DB: aicmo
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U aicmo -d aicmo"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10
    env:
      DATABASE_URL: postgresql+psycopg2://aicmo:pass@localhost:5435/aicmo
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -m venv .venv
          . .venv/bin/activate
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
          # --- FIX ---
          # Removed '|| true' to ensure test dependency failures stop the build
          pip install -r backend/requirements-test.txt

      - name: Prep DB + migrate
        run: |
          . .venv/bin/activate
          PSQL_URL=$(python - <<'PY'
          import os,re; u=os.environ['DATABASE_URL']; print(re.sub(r'^(postgresql)(?:\+[^:]+)?://','postgresql://',u))
          PY
          )
          # Clean schema each run
          psql "$PSQL_URL" -c "DROP SCHEMA IF EXISTS public CASCADE; CREATE SCHEMA public;"

          # Single-head guard
          alembic -c backend/alembic.ini heads | awk 'END{ if (NR!=1) { print "Multiple Alembic heads!"; exit 1 } }'

          # Apply migrations
          alembic -c backend/alembic.ini upgrade head

          # === Schema asserts (fail fast) ===
          # (These are optional but good asserts, kept from your example)
          psql "$PSQL_URL" -Atc "SELECT 1 FROM pg_indexes WHERE tablename='site' AND indexname='ux_site_slug';" | grep 1
          psql "$PSQL_URL" -Atc "SELECT indexdef FROM pg_indexes WHERE tablename='page' AND indexdef LIKE '%UNIQUE% (site_id, path)%';" | grep UNIQUE
          psql "$PSQL_URL" -Atc "SELECT table_name FROM information_schema.views WHERE table_schema='public' AND table_name='site_spec';" | grep site_spec

      - name: Alembic visibility check
        working-directory: .
        run: |
          set -e
          . .venv/bin/activate
          echo "CWD: $(pwd)"
          echo "Repo root listing:"
          ls -la
          echo "Alembic files:"
          ls -la backend/alembic || true
          ls -la backend/alembic/versions || true

          python - <<'PY'
          import os, glob
          from alembic.config import Config
          from alembic.script import ScriptDirectory

          cfg = Config("backend/alembic.ini")
          print("alembic.ini found:", os.path.exists("backend/alembic.ini"))
          print("cfg.config_file_name:", cfg.config_file_name)
          print("script_location cfg:", cfg.get_main_option("script_location"))

          versions = glob.glob("backend/alembic/versions/*.py")
          print("versions count:", len(versions))
          for v in sorted(versions)[-5:]:
              print("  -", os.path.basename(v))

          script = ScriptDirectory.from_config(cfg)
          print("heads:", list(script.get_heads()))
          print("bases:", list(script.get_bases()))
          PY

      - name: Ensure DB client + driver and set DATABASE_URL
        run: |
          python -m pip install --upgrade pip
          python -m pip install psycopg2-binary sqlalchemy
          # Use the service hostname "postgres" inside the job network
          echo "DATABASE_URL=postgresql+psycopg2://aicmo:pass@postgres:5432/aicmo" >> $GITHUB_ENV
          # Sanity check the connection
          python - <<'PY'
          import os, sys
          from sqlalchemy import create_engine, text
          url = os.environ.get("DATABASE_URL")
          assert url, "DATABASE_URL not set"
          eng = create_engine(url, pool_pre_ping=True)
          with eng.connect() as c:
              c.execute(text("SELECT 1"))
          print("[dbg] DB connectivity OK:", url)
          PY

      - name: Alembic heads/current (no DB) — prove versions are visible
        working-directory: .
        run: |
          python - <<'PY'
          from alembic.config import Config
          from alembic.script import ScriptDirectory
          cfg = Config("backend/alembic.ini")
          print("[dbg] config_file_name =", cfg.config_file_name)
          print("[dbg] script_location  =", cfg.get_main_option("script_location"))
          sd = ScriptDirectory.from_config(cfg)
          heads = list(sd.get_heads())
          bases = list(sd.get_bases())
          print("[dbg] heads =", heads)
          print("[dbg] bases =", bases)
          assert heads, "No heads found — Alembic cannot see versions"
          PY

      - name: DB alembic_version (optional)
        if: ${{ env.DATABASE_URL != '' }}
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: |
          python - <<'PY'
          import os
          from sqlalchemy import create_engine, text
          url = os.environ.get("DATABASE_URL","")
          if not url:
              print("[dbg] No DATABASE_URL set; skipping DB version check.")
          else:
              print("[dbg] DATABASE_URL present; querying alembic_version …")
              eng = create_engine(url, future=True)
              with eng.connect() as c:
                  try:
                      v = c.execute(text("SELECT version_num FROM alembic_version")).scalar()
                      print("[dbg] alembic_version.version_num =", v)
                  except Exception as e:
                      print("[dbg] Could not read alembic_version:", e)
          PY

      - name: Drift probe (fail if model != DB)
        working-directory: .
        run: |
          . .venv/bin/activate
          python - <<'PY'
          import os, tempfile, pathlib, sys
          from alembic.config import Config
          from alembic import command

          repo_versions = os.path.abspath('backend/alembic/versions')
          tmp = pathlib.Path(tempfile.mkdtemp(prefix='alembic_probe_'))
          out = tmp / 'versions'
          out.mkdir(parents=True, exist_ok=True)

          cfg = Config('backend/alembic.ini')
          print('[dbg] CWD:', os.getcwd())
          print('[dbg] backend/alembic.ini exists:', os.path.exists('backend/alembic.ini'))
          print('[dbg] cfg.config_file_name:', cfg.config_file_name)
          print('[dbg] cfg.script_location (before):', cfg.get_main_option('script_location'))

          # Ensure alembic can resolve repo revisions while writing to a temp versions dir
          cfg.set_main_option('script_location', 'backend/alembic')
          cfg.set_main_option('version_locations', f"{out},{repo_versions}")
          print('[dbg] cfg.script_location (after):', cfg.get_main_option('script_location'))
          print('[dbg] cfg.version_locations (after):', cfg.get_main_option('version_locations'))

          # List repo versions for visibility
          try:
              rv = list(pathlib.Path(repo_versions).glob('*.py'))
              print('[dbg] repo versions count:', len(rv))
              for v in sorted(rv)[-20:]:
                  print('  -', v.name)
          except Exception as e:
              print('[dbg] listing repo versions failed:', e)

          # Show what exists in the repo's versions dir
          repo_versions_dir = repo_versions
          rv_path = pathlib.Path(repo_versions_dir)
          files = sorted(p.name for p in rv_path.glob('*.py')) if rv_path.exists() else []
          print(f"[dbg] repo versions count={len(files)}")
          for n in files[:20]:
              print(f"[dbg]   - {n}")
          if len(files) > 20:
              print(f"[dbg]   ... (+{len(files)-20} more)")

          # NEW: fail fast if no repo migrations are visible
          assert files, "No migrations found in backend/alembic/versions — ensure actions/checkout uses fetch-depth: 0"

          try:
              command.revision(cfg, message='DRIFT_PROBE', autogenerate=True, version_path=str(out))
          except SystemExit:
              pass

          files = list(out.glob('*.py'))
          dst = pathlib.Path('.alembic_autogen/drift_pg')
          dst.mkdir(parents=True, exist_ok=True)
          if files:
              print('Autogenerate produced diffs → drift detected.')
              for f in files:
                  print(' -', f.name)
                  (dst / f.name).write_text(f.read_text(encoding='utf-8'))
              print('Wrote authoritative PG autogen to', dst)
              # Leave destructive scanning to the later dedicated step
              sys.exit(1)
          else:
              print('No drift.')
          PY

      - name: Run tests (Postgres + SQLite)
        env:
          DATABASE_URL: postgresql+psycopg2://aicmo:pass@localhost:5435/aicmo
        run: |
          . .venv/bin/activate
          pytest -q

      - name: Alembic visibility check (list heads from real script_location)
        working-directory: .
        run: |
          python - <<'PY'
          import os
          from alembic.config import Config
          from alembic.script import ScriptDirectory

          cfg = Config("backend/alembic.ini")
          script_location = cfg.get_main_option("script_location")
          print(f"[dbg] real script_location={script_location}")

          sd = ScriptDirectory.from_config(cfg)
          heads = list(sd.get_heads())
          print(f"[dbg] alembic heads count={len(heads)} -> {heads}")
          assert len(heads) >= 1, "No heads found — Alembic cannot see versions"
          PY

      - name: Prune non-probe files from PG drift artifact
        if: always()
        run: |
          set -euo pipefail
          ROOT=".alembic_autogen/drift_pg"
          [ -d "$ROOT" ] || exit 0
          echo "[guard] keeping files that match '*drift_probe*.py' only"
          find "$ROOT" -type f -name "*.py" ! -name "*drift_probe*.py" -print -delete || true
          echo "[guard] remaining files:"; find "$ROOT" -type f -maxdepth 2 -print || true

      - name: Scan drift artifacts for destructive changes
        if: always()
        run: |
          python tools/scan_autogen_for_drops.py .alembic_autogen/drift_pg || (echo "Destructive tokens detected" && exit 1)
