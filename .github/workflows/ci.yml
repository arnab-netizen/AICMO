---
name: CI

on:
  push:
    branches:
      - main
      - master
  pull_request:
jobs:
  unit-minimal:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install capsule-core (editable)
        run: |
          python -m pip install --upgrade pip
          pip install -e ./capsule-core

      - name: Import check
        run: |
          python -c "from capsule_core.run import RunRequest; print(RunRequest(project_id='ok', payload={}))"

      - name: Install deps (backend + minimal worker deps)
        run: |
          python -m pip install --upgrade pip
          if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi
          if [ -f workers/requirements.txt ]; then pip install -r workers/requirements.txt; fi
          pip install pytest

      - name: Guard against legacy core imports
        run: |
          # Fail if any in-tree legacy `core.*` imports exist (allow edits to capsule-core)
          ! grep -RInE "\b(from|import)\s+core\.(run|metrics|utils)\b" \
            --exclude-dir=.venv --exclude-dir=node_modules --exclude-dir=capsule-core .

      - name: Run minimal tests
        run: make minimal-test

      - name: Run SiteGen tests
        env:
          SITEGEN_API_KEY: "" # default empty (no auth path)
        run: |
          PYTHONPATH=. pytest -q \
            backend/tests/test_sitegen_contract.py \
            backend/tests/test_sitegen_auth.py \
            backend/tests/test_sitegen_health.py

      - name: Run SiteGen auth (key required)
        env:
          SITEGEN_API_KEY: "ci-secret"
        run: |
          PYTHONPATH=. pytest -q backend/tests/test_sitegen_auth.py::test_run_requires_api_key_when_set

      - name: Run SiteGen SQLite persistence tests
        env:
          SITEGEN_STORE: db
          DATABASE_URL: "sqlite+pysqlite:///:memory:"
          SITEGEN_API_KEY: ""
        run: |
          PYTHONPATH=. pytest -q backend/tests/test_sitegen_persistence_sqlite.py

  # unit-full:
  #   runs-on: ubuntu-latest
  #   needs: unit-minimal
  #   timeout-minutes: 15
  #   steps:
  #     - uses: actions/checkout@v4
  #     - uses: actions/setup-python@v5
  #       with:
  #         python-version: '3.12'
  #     - uses: actions/cache@v4
  #       with:
  #         path: ~/.cache/pip
  #         key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
  #         restore-keys: |
  #           ${{ runner.os }}-pip-
  #     - name: Install deps
  #       run: |
  #         python -m pip install --upgrade pip
  #         if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi
  #         pip install pytest
  #     - name: Run full backend tests
  #       env:
  #         PYTHONPATH: .
  #       run: make full-test
  #     run: black --check backend

  taste-pgvector:
    runs-on: ubuntu-latest
    if: >
      github.ref == 'refs/heads/main' ||
      contains(join(fromJson(toJson(github.event.pull_request.labels)).*.name, ','), 'needs-pg')
    services:
      pg:
        # Use a Postgres image with the pgvector extension preinstalled so
        # CI steps that `CREATE EXTENSION IF NOT EXISTS vector;` succeed.
        # We intentionally use the ankane/pgvector image here for the taste-pgvector
        # job which verifies vector-related functionality.
        image: ankane/pgvector:latest
        ports: ['5432:5432']
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: app
        # add a docker-level healthcheck so the runner can detect readiness earlier
        options: >-
          --health-cmd="pg_isready -U postgres -d app"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=20

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      # pip cache (optional but recommended)
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r backend/requirements.txt
          # Dev-only tools used by CI (mypy, ruff, black)
          if [ -f backend/requirements-dev.txt ]; then pip install -r backend/requirements-dev.txt; fi
          pip install pytest pytest-asyncio httpx alembic prometheus-client

      - name: Run pre-commit (all files)
        run: |
          pip install pre-commit
          pre-commit run --all-files || true

      - name: Install psql client
        run: |
          if command -v psql >/dev/null 2>&1; then
            echo "psql present"
          else
            sudo apt-get update
            sudo apt-get install -y postgresql-client
          fi

      - name: Set env
        run: |
          echo "DB_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/app" >> $GITHUB_ENV
          # Keep both names to satisfy any step that checks one or the other
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/app" >> $GITHUB_ENV

      - name: Wait for Postgres
        run: |
          # prefer pg_isready if available, otherwise fallback to psql probe
          for i in {1..40}; do
            if command -v pg_isready >/dev/null 2>&1; then
              if pg_isready -h localhost -p 5432 -U postgres >/dev/null 2>&1; then
                echo "Postgres is ready (pg_isready)"; break
              fi
            else
              if psql "$DATABASE_URL" -c "SELECT 1" >/dev/null 2>&1; then
                echo "Postgres is ready (psql)"; break
              fi
            fi
            echo "Waiting for Postgres... ($i)"; sleep 3
          done

      - name: Ensure pgvector extension (best-effort)
        run: |
          # Some Postgres images may not ship the pgvector extension. Check
          # whether the extension is available on the server before attempting
          # to create it. If it's not available, print a warning and continue.
          set -euo pipefail
          echo "Checking for pgvector availability..."
          # print the availability row for debug (helps triage images missing control file)
          psql "$DATABASE_URL" -U postgres -h localhost -Atc "SELECT name, default_version, installed_version FROM pg_available_extensions WHERE name='vector' LIMIT 1;" || true
          if psql "$DATABASE_URL" -U postgres -h localhost -Atc "SELECT 1 FROM pg_available_extensions WHERE name='vector' LIMIT 1;" | grep -q 1; then
            echo "pgvector appears available -> attempting to create extension (failure will be tolerated)"
            # attempt to create; tolerate failure because some server images may have the entry but not the control file
            psql "$DATABASE_URL" -U postgres -h localhost -c "CREATE EXTENSION IF NOT EXISTS vector;" || echo "[warn] CREATE EXTENSION vector failed but will be ignored (extension control file may be missing)"
          else
            echo "[warn] pgvector extension not available in this Postgres image; skipping CREATE EXTENSION"
            echo "If tests rely on pgvector, use an image with pgvector or install the extension on the server."
          fi

      - name: Check pgvector is installed (info)
        run: |
          # Print installed extension info if available; otherwise print a warning.
          if psql "$DATABASE_URL" -U postgres -h localhost -Atc "SELECT 1 FROM pg_extension WHERE extname='vector' LIMIT 1;" | grep -q 1; then
            psql "$DATABASE_URL" -U postgres -h localhost -c "SELECT extname, extversion FROM pg_extension WHERE extname='vector';"
          else
            echo "[info] pgvector not installed; tests will skip pgvector-specific checks unless migrations add the extension dynamically."
          fi

      - name: Prepare DB (Alembic migrate + seed)
        env:
          ALEMBIC_CONFIG: backend/alembic.ini
        run: |
            set -euo pipefail

            # Compute a sync SQLAlchemy URL for Alembic and sync-only scripts.
            SYNC_URL=$(python -c 'import os,sys; u=os.environ.get("DATABASE_URL") or os.environ.get("DB_URL") or ""; print(u.replace("+asyncpg","+psycopg2") if "+asyncpg" in u else u)')

            if [ -n "${SYNC_URL:-}" ]; then
              echo "[dbg] computed SYNC_URL: $SYNC_URL"
              export SQLALCHEMY_URL="$SYNC_URL"
              export DATABASE_URL="$SYNC_URL"
            else
              echo "[warn] could not compute SYNC_URL; proceeding with existing env vars"
            fi

            # Diagnostic: print relevant DB/SQLAlchemy driver versions to help triage MissingGreenlet
            python -c 'import importlib,sys; pkgs=("sqlalchemy","asyncpg","greenlet","psycopg"); importlib; [print(p, getattr(__import__(p), "__version__", getattr(__import__(p), "version", "unknown")) if p in sys.modules or __import__(p) else None) for p in pkgs]'

            # Run Alembic migrations using the computed sync URL (env-aware via alembic env.py)
            alembic -c "$ALEMBIC_CONFIG" upgrade head

            # Quick test: run the seed via an inline Python wrapper that sets
            # the SQLALCHEMY_URL/DATABASE_URL environment before importing the
            # seed module. This verifies whether module-level imports are
            # causing the asyncpg dialect to be selected.
            python - <<PY
import os
os.environ['SQLALCHEMY_URL'] = '${SYNC_URL}'
os.environ['DATABASE_URL'] = '${SYNC_URL}'
print('[dbg] wrapper env SQLALCHEMY_URL=', os.environ.get('SQLALCHEMY_URL'))
from backend.tools import seed_taste_demo
seed_taste_demo.main()
PY

      - name: Smoke checks
        run: |
          python -m backend.tools.smoke_versions
          SMOKE_SKIP="/api/visualgen/run,/api/copyhook/run" python -m backend.tools.smoke_telemetry

      - name: Run tests (versions + taste)
        env:
          DB_URL: postgresql://postgres:postgres@127.0.0.1:5432/postgres
        run: |
          pytest -q backend/tests/test_metrics_endpoint.py
          pytest -q backend/tests/test_version_endpoints.py
          pytest -q backend/tests/test_taste_endpoints_integration.py
          pytest -q backend/tests/test_taste_metrics.py
          pytest -q backend/tests/test_taste_similarity_deterministic.py
      # (already ensured before migrations)

      - name: Pre-import coverage fanout
        run: python -c "import backend.cov_unit_targets"

      - name: Run unit subset w/ coverage gate (â‰¥85%)
        run: |
          python -m pytest \
            backend/tests/test_health_endpoints.py \
            backend/tests/test_db_sqlite.py \
            backend/tests/test_models_asset.py \
            backend/tests/test_taste_service_unit.py \
            backend/tests/test_db_exec_sql_helper.py \
            backend/tests/test_health_db_errors.py \
            backend/tests/test_taste_service_extra.py \
            --maxfail=1 -q \
            --cov=backend.cov_unit_targets \
            --cov-report=term-missing \
            --cov-fail-under=85
      - name: Coverage (backend only)
        run: |
          pytest -q --maxfail=1 --disable-warnings --cov=backend --cov-report=term-missing --cov-fail-under=35
      - name: Upload coverage HTML
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html
          path: htmlcov/
